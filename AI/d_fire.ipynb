{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaacdef-12d4-4c8e-9f6e-839aff81e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "import os\n",
    "from  ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5966f9-9149-4b1c-aa0c-64ad2ca6943c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "dataset = \"./D-Fire/\"\n",
    "data = {\n",
    "    'names': ['fire', 'smoke'],\n",
    "    'nc': 2,\n",
    "    'val': 'test/images',\n",
    "    'train': 'train/images'\n",
    "}\n",
    "\n",
    "# YAML 파일로 저장\n",
    "with open(f'{dataset}data.yaml', 'w') as file:\n",
    "    yaml.dump(data, file)\n",
    "\n",
    "print(\"YAML 파일이 생성되었습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26bab9e-98c2-455c-9e8f-867b3a8b2956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.121 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.119  Python-3.10.11 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=C:/Users/LGS/Desktop/STEP_7/fire_det/D-Fire//data.yaml, epochs=50, patience=50, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train23\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8719894  ultralytics.nn.modules.head.Detect           [2, [320, 640, 640]]          \n",
      "Model summary: 365 layers, 68154534 parameters, 68154518 gradients, 258.1 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train23', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\labels.cache... 17221 images, 7833 backgrounds, 0 corrupt: 100%|██████████| 17221/17221 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB02521.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB06626.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07199.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07271.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07278.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07297.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07305.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07312.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07534.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07535.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07536.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07538.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07539.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07540.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07541.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07542.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07543.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07552.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07554.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07555.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07556.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07557.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07559.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07561.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07562.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\train\\images\\WEB07639.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\labels.cache... 4306 images, 2005 backgrounds, 8 corrupt: 100%|██████████| 4306/4306 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB10769.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0297]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB10770.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0078]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB10775.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0156]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB10821.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0094]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11090.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11243.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11244.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11245.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11313.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11315.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11316.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11319.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11320.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11321.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11322.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11323.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11598.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0359]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11600.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0562]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\LGS\\Desktop\\STEP_7\\fire_det\\D-Fire\\test\\images\\WEB11606.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0028]\n",
      "Plotting labels to runs\\detect\\train23\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train23\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50      24.8G      1.508      1.858      1.528         12        640: 100%|██████████| 539/539 [08:11<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:47<00:00,  1.43it/s]\n",
      "                   all       4298       5176      0.557        0.5      0.515      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50      24.6G      1.496      1.426      1.476         10        640: 100%|██████████| 539/539 [08:04<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:47<00:00,  1.44it/s]\n",
      "                   all       4298       5176       0.57      0.514      0.539      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50      24.8G      1.616      1.611      1.564         20        640: 100%|██████████| 539/539 [07:58<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:49<00:00,  1.37it/s]\n",
      "                   all       4298       5176      0.412      0.424       0.38      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50      24.9G      1.691      1.757      1.631          6        640: 100%|██████████| 539/539 [08:01<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:45<00:00,  1.51it/s]\n",
      "                   all       4298       5176      0.559      0.493      0.508       0.25\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50      24.8G      1.623      1.625      1.591          5        640: 100%|██████████| 539/539 [07:56<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:46<00:00,  1.47it/s]\n",
      "                   all       4298       5176      0.578      0.531      0.553      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50      24.9G      1.581      1.513      1.558         11        640: 100%|██████████| 539/539 [07:58<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:46<00:00,  1.47it/s]\n",
      "                   all       4298       5176      0.599      0.566      0.586        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50      24.8G      1.528       1.43      1.525         23        640: 100%|██████████| 539/539 [07:55<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:45<00:00,  1.49it/s]\n",
      "                   all       4298       5176      0.627       0.51      0.551      0.285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50      24.6G      1.496      1.374        1.5         12        640: 100%|██████████| 539/539 [07:55<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:46<00:00,  1.46it/s]\n",
      "                   all       4298       5176      0.663      0.597      0.639      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50      24.8G      1.468      1.321      1.486         23        640: 100%|██████████| 539/539 [07:56<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:45<00:00,  1.48it/s]\n",
      "                   all       4298       5176      0.662      0.608      0.659      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50      24.9G      1.452      1.293      1.466          5        640: 100%|██████████| 539/539 [08:02<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:45<00:00,  1.49it/s]\n",
      "                   all       4298       5176      0.683      0.618      0.676      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50      24.7G      1.431      1.242      1.453          8        640: 100%|██████████| 539/539 [07:56<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:45<00:00,  1.49it/s]\n",
      "                   all       4298       5176      0.687      0.631      0.689      0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50      24.9G      1.407      1.218      1.433         10        640: 100%|██████████| 539/539 [07:56<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:45<00:00,  1.51it/s]\n",
      "                   all       4298       5176      0.705      0.651      0.711      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50      24.8G       1.39      1.184      1.423          7        640: 100%|██████████| 539/539 [07:57<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:45<00:00,  1.51it/s]\n",
      "                   all       4298       5176      0.693      0.655      0.707      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50      24.9G      1.379       1.15      1.419          4        640: 100%|██████████| 539/539 [08:02<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:44<00:00,  1.52it/s]\n",
      "                   all       4298       5176      0.724      0.658       0.72      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50      24.8G      1.365      1.129       1.41         22        640: 100%|██████████| 539/539 [08:00<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:44<00:00,  1.52it/s]\n",
      "                   all       4298       5176      0.732       0.67      0.735      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50      24.9G      1.346      1.102      1.394         16        640: 100%|██████████| 539/539 [07:59<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:44<00:00,  1.54it/s]\n",
      "                   all       4298       5176      0.721      0.678      0.733      0.414\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50      24.8G      1.333      1.081      1.384         72        640:  90%|█████████ | 487/539 [07:15<00:46,  1.12it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"  # Set the GPU 2 to use\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import timeit\n",
    "dataset = \"C:/Users/LGS/Desktop/STEP_7/fire_det/D-Fire/\"\n",
    "# predict on a local image\n",
    "model = YOLO(\"yolov8x.pt\")\n",
    "model.train(data=f\"{dataset}/data.yaml\", \n",
    "            epochs=50,\n",
    "           batch = 32) #s -> 64 -> 15.8g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e184dfb-3cbf-44c2-a55e-359da229ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import timeit\n",
    "\n",
    "model = YOLO('C:/Users/LGS/Desktop/STEP_7/fire_det/runs/detect/train23/weights/best.pt')\n",
    "video_name = \"test_fire\"\n",
    "video_path = f\"C:/Users/LGS/Desktop/STEP_7/fire_det/test_mp4/{video_name}.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "out = cv2.VideoWriter(f'{video_name}_result.mp4', fourcc, cap.get(5), (int(cap.get(3)),int(cap.get(4))))\n",
    "# out2 = cv2.VideoWriter('pose.mp4', fourcc, cap.get(5), (int(cap.get(3)),int(cap.get(4))))\n",
    "\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model.predict(frame,verbose = False, conf = 0.7)[0]\n",
    "        \n",
    "        # Visualize the results on the frame\n",
    "        tracking = results.plot(prob = False, conf = False)\n",
    "        terminate_time = timeit.default_timer()\n",
    "        fps = str(int(1./(terminate_time - start_time )))\n",
    "        # cv2.rectangle(tracking,(0,0), (150,50), (255,255,255), -1)\n",
    "        # cv2.putText(tracking, \"fps = {} \".format(fps), (0, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0))\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", tracking)\n",
    "        \n",
    "        out.write(tracking)\n",
    "        # out2.write(pose_tracking)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "out.release()\n",
    "# out2.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28194749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_data = json.loads(results.tojson())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8ff239f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-26 14:14:17.749888 smoke\n",
      "2023-06-26 14:14:17.749888 fire\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for label in json_data:\n",
    "    print(datetime.now(),label['name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
